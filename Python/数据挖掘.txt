数据挖掘过程
	1、定义目标
	2、获取数据（爬虫或下载）
	3、数据探索
	4、数据与处理（数据清洗【去掉脏数据】、数据集成【集中】、数据变换【规范化】、数据规约【精简】）
	5、挖掘建模（分类、聚类、关联、预测）
	6、模型评价与发布

相关模块的使用
	1、numpy可以高效处理数据、提供数组支持、很多模块都依赖他，比如 Pandas 、scipy、matp1ot1ib都依赖他，所以这个模块是基础。
	2、pandas 我们课程后续用得最多的一个模块，主要用于进行数据探索和数据分析。
	3、matp1ot1ib 作图模块，解决可视化问题。
	4、scipy主要进行数值计算，同时支持矩阵运算，并提供了很多高等数据处理功能，比如积分、傅里叶变换、微分方程求解等。
	5、statsmodels这个模块主要用于统计分析
	6、Gensim这个模块主要用于文本挖掘
	7、sklearn、keras前者机器学习，后者深度学习
安装
	下载安装numpy+mkl模块
	网络安装pandas模块
	网络安装matp1ot1ib模块
	下载安装scipy模块
	网络安装statsmodels模块
	网络安装gensim模块
相关模块使用
	numpy
	pandas
	matplotlib
数据处理
	数据探索
	数据清洗
	数据集成
数据转换属性构造数据规约
	简单变换
	数据规范化（离差标准化、标准差标准化）
	离散化（等靠宽离散化）
	属性构造
	属性规约与数值规约（PCA主成分分析 降维分析）（sklearn[网络]安装PCA模块）
文本挖掘（jieba模块文本分析）
文本相似度分析
	tf-idf算法、稀疏向量（？）
	1、读取文档
	2、对要计算的多篇文档进行分词
	3、对文档进行整理成指定格式．方便后续进行计算
	4、计算出词语的频率 
	5、【 可选 】 、对频率低的词语进行过滤
	6、通过语料库建立词典
	7、加载要对比的文档
	8、将要对比的文档通过docZbow昨转化为稀疏向量
	9、对稀疏向量进行进一步处理，得到新语科库
	10、将新语料库通过tfidfmodel进行处理，得到tfidf
	11、通过token2id记得到特征数
	12、稀疏矩阵相似度．从而建立索引
	13、得到最终相似度结果
数据建模概述
	常见模型建立算法，分类、聚类、关联、回归等
常见分类算法
	KNN算法（手写体数据识别，验证码识别）、
	贝叶斯算法、
	回归算法（逻辑回归）
	决策树（ID3、C4.5、CART）（Graphviz辅助软件dot文件转换）、
	人工智能网络、
	支持向量机
聚类算法（划分（分裂）法、层次分析法、密度分析法）、网格法、模型法
	kmeans算法k平均算法
	k中心点算法
	代表点聚类
	动态模型聚类
	平衡迭代规约聚类
	密度分布函数聚类
神经网络（分类算法）激活函数（域值函数、Relu函数、线性分段函数、非线性转移函数）（阈值）
具体人工神经网络模型（网络安装keras模块）
	BP神经网络
	RBF竟向基神经网络
	FNN
	LM神经网络：精准度非常高
		神经网络手写体识别实战②
关联分析
	支持度、置信度


PhantomJS获取数据（爬虫）、urllib、Scrapy、通过接口（微博开放接口获取数据）
BloomFilter布隆过滤器

杂项
MNIST数据集
CNN卷积神经网络
LeNet5神经网络
kaggle项目
Dropout relu adam
softmax






